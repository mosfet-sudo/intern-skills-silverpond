{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Train A Shape Classifier Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create simple plots and visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#use common neural network operations like activations and loss functions.\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#ImageIO:open, edit, and save image files \n",
    "from PIL import Image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and write data in JSON format, simple for configs and annotations.\n",
    "import json\n",
    "import os\n",
    "\n",
    "train_data_root = \"../datasets/train\"\n",
    "test_data_root = \"../datasets/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, torch\n",
    "print(sys.executable)\n",
    "print(\"torch version:\", torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define transformations (including resizing and normalization)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  # Convert to grayscale (black and white images)\n",
    "    transforms.Resize((64, 64)),  # Resize images to 64x64 pixels\n",
    "    transforms.ToTensor(),  # Convert the image to a tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize the images (mean=0.5, std=0.5 for grayscale)\n",
    "])\n",
    "\n",
    "# Load the dataset\n",
    "train_dataset = datasets.ImageFolder(root=train_data_root, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=test_data_root, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Check class names (optional)\n",
    "print(f'Classes: {train_dataset.classes}')\n",
    "\n",
    "# 2. Define a simple CNN model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        # self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 16 * 16, 128)\n",
    "        self.fc2 = nn.Linear(128, 3)  # 3 classes: circle, triangle, rectangle\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))   # First Conv Layer\n",
    "        x = F.max_pool2d(x, 2)      # Max Pooling\n",
    "        x = F.relu(self.conv2(x))   # Second Conv Layer\n",
    "        x = F.max_pool2d(x, 2)      # Max Pooling\n",
    "        x = x.view(x.size(0), -1)   # Flatten\n",
    "        x = F.relu(self.fc1(x))     # Fully Connected Layer 1\n",
    "        x = self.fc2(x)             # Fully Connected Layer 2 (output)\n",
    "        return x\n",
    "\n",
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # accuracy = 0 * correct / total\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, train_loader, criterion, optimizer, epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the main PyTorch library for working with tensors and neural networks.\n",
    "import torch\n",
    "# Import the functional API from torch.nn as F for convenient neural network operations.\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Use inference_mode decorator to run this function without gradient tracking for faster, memory-efficient testing.\n",
    "@torch.inference_mode()\n",
    "# Define a function to evaluate the model on the test set using a given data loader.\n",
    "def test(model, test_loader):\n",
    "    \"\"\"Evaluate model on test set and print per-class & macro Precision/Recall/F1.\"\"\"\n",
    "    \n",
    "    # Get the device (CPU or GPU) that the model is using so we can send data to the same place.\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    # Put the model into evaluation mode so layers like dropout and batchnorm behave correctly for testing.\n",
    "    model.eval()\n",
    "    # Create an empty list to store predictions for all test samples.\n",
    "    all_preds = []\n",
    "    # Create an empty list to store true labels for all test samples.\n",
    "    all_labels = []\n",
    "\n",
    "    # Loop over all batches from the test loader to process the entire test dataset.\n",
    "    for images, labels in test_loader:\n",
    "        # Move the input images to the same device as the model.\n",
    "        images = images.to(device)\n",
    "        # Move the labels to the same device as the model.\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Run the model on this batch of images to get class scores for each sample.\n",
    "        outputs = model(images)\n",
    "        # Take the index of the maximum score along the class dimension as the predicted class for each sample.\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "        # Store this batch's predictions on the CPU so we can combine them later.\n",
    "        all_preds.append(preds.cpu())\n",
    "        # Store this batch's true labels on the CPU so we can combine them later.\n",
    "        all_labels.append(labels.cpu())\n",
    "\n",
    "    # Concatenate all prediction tensors from each batch into one long tensor for the whole test set.\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    # Concatenate all label tensors from each batch into one long tensor for the whole test set.\n",
    "    all_labels = torch.cat(all_labels)\n",
    "\n",
    "    # Get the number of classes from the dataset so we know how big the confusion matrix should be.\n",
    "    num_classes = len(test_loader.dataset.classes)\n",
    "    # Get the list of class names from the dataset so we can print human-readable results.\n",
    "    class_names = test_loader.dataset.classes\n",
    "\n",
    "    # Create an empty confusion matrix where rows are true labels and columns are predicted labels.\n",
    "    conf_mat = torch.zeros((num_classes, num_classes), dtype=torch.int64)\n",
    "\n",
    "    # Loop over all true–predicted pairs to fill in the confusion matrix counts.\n",
    "    for t, p in zip(all_labels, all_preds):\n",
    "        # Increase the counter for this (true class, predicted class) position by one.\n",
    "        conf_mat[t, p] += 1\n",
    "\n",
    "    # Take the diagonal elements of the confusion matrix as true positives for each class.\n",
    "    TP = conf_mat.diag().float()\n",
    "    # Sum over columns to get how many samples were predicted as each class.\n",
    "    pred_counts = conf_mat.sum(dim=0).float()\n",
    "    # Sum over rows to get how many samples actually belong to each class.\n",
    "    true_counts = conf_mat.sum(dim=1).float()\n",
    "\n",
    "    # Compute per-class precision as TP divided by predicted positives with a small epsilon to avoid division by zero.\n",
    "    precision_per_class = TP / (pred_counts + 1e-8)\n",
    "    # Compute per-class recall as TP divided by actual positives with a small epsilon to avoid division by zero.\n",
    "    recall_per_class    = TP / (true_counts + 1e-8)\n",
    "    # Compute per-class F1 score as the harmonic mean of precision and recall with a small epsilon in the denominator.\n",
    "    f1_per_class        = 2 * precision_per_class * recall_per_class / (\n",
    "        precision_per_class + recall_per_class + 1e-8\n",
    "    )\n",
    "\n",
    "    # Compute the macro (unweighted) average precision across all classes and convert to a Python float.\n",
    "    macro_precision = precision_per_class.mean().item()\n",
    "    # Compute the macro (unweighted) average recall across all classes and convert to a Python float.\n",
    "    macro_recall    = recall_per_class.mean().item()\n",
    "    # Compute the macro (unweighted) average F1 score across all classes and convert to a Python float.\n",
    "    macro_f1        = f1_per_class.mean().item()\n",
    "\n",
    "    # Print the confusion matrix so we can see how predictions are distributed across classes.\n",
    "    print(\"Confusion matrix:\\n\", conf_mat.numpy())\n",
    "    print()\n",
    "\n",
    "    # Loop over each class index and name to print its individual metrics.\n",
    "    for i, name in enumerate(class_names):\n",
    "        # Print precision, recall, and F1 score for this specific class in a formatted line.\n",
    "        print(\n",
    "            f\"Class '{name}': \"\n",
    "            f\"P={precision_per_class[i]:.3f}, \"\n",
    "            f\"R={recall_per_class[i]:.3f}, \"\n",
    "            f\"F1={f1_per_class[i]:.3f}\"\n",
    "        )\n",
    "\n",
    "    print()\n",
    "    # Print the macro-averaged precision, recall, and F1 score as a summary of overall performance.\n",
    "    print(\n",
    "        f\"Macro Precision: {macro_precision:.3f}, \"\n",
    "        f\"Macro Recall: {macro_recall:.3f}, \"\n",
    "        f\"Macro F1: {macro_f1:.3f}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the test function to evaluate the trained model on the test_loader and print all metrics.\n",
    "\n",
    "test(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "# Show Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pyplot module from Matplotlib to create simple visualizations like showing images and adding titles (very beginner-friendly for plotting).\n",
    "import matplotlib.pyplot as plt\n",
    "# Import the Image class from the Pillow (PIL) library so we can easily open and handle image files.\n",
    "from PIL import Image\n",
    "# Import the functional API from PyTorch as F so we can conveniently apply functions like softmax to model outputs.\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Use inference_mode so this function runs without tracking gradients, which is faster and safer for pure prediction.\n",
    "@torch.inference_mode()\n",
    "# Define a helper function that runs the model on a single image and visualizes the prediction result.\n",
    "def show_prediction(\n",
    "    model,\n",
    "    image_path: str,\n",
    "    transform,\n",
    "    class_names,\n",
    "    true_label_idx: int | None = None,\n",
    "    ax=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Make predictions for a single image and visualize the results.\n",
    "\n",
    "    `model: nn.Module` The trained CNN model.\n",
    "\n",
    "    `image_path: str` The path to the input image.\n",
    "\n",
    "    `transform: torchvision.transforms.Compose` The exact same transform as during training/testing.\n",
    "\n",
    "    `class_names: list[str]` A list of class names, e.g., ['circle', 'diamond', 'triangle'].\n",
    "\n",
    "    `true_label_idx: int, optional` The index of the true label (if any, used to display 'GT→Pred').\n",
    "\n",
    "    If None, only Pred is displayed.\n",
    "\n",
    "    `ax: matplotlib.axes.Axes, optional` Pass in an existing subplot axis; if None, a new figure is created.\n",
    "     \"\"\"\n",
    "\n",
    "    # Get the device (CPU or GPU) where the model’s parameters live so we can send data to the same place.\n",
    "    device = next(model.parameters()).device\n",
    "    # Put the model into evaluation mode so layers like dropout and batchnorm behave correctly for inference.\n",
    "    model.eval()\n",
    "\n",
    "    # Load the image from disk as a PIL image and convert it to RGB format for consistent processing.\n",
    "    img_pil = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "    # Apply the same preprocessing as in training, add a batch dimension, and move the tensor to the model’s device.\n",
    "    img_tensor = transform(img_pil).unsqueeze(0).to(device)   # [1, C, H, W]\n",
    "\n",
    "    # Run a forward pass through the model to get raw class scores (logits) for this image.\n",
    "    logits = model(img_tensor)                     # [1, num_classes]\n",
    "    # Apply softmax to convert logits into probabilities and move the result back to CPU.\n",
    "    probs = F.softmax(logits, dim=1).squeeze(0).cpu()  # [num_classes]\n",
    "\n",
    "    # Find the index of the class with the highest probability as the predicted label.\n",
    "    pred_idx = int(torch.argmax(probs))\n",
    "    # Get the confidence (probability) of the predicted class as a plain Python float.\n",
    "    pred_conf = float(probs[pred_idx])  # 0~1\n",
    "    # Look up the human-readable class name for the predicted class index.\n",
    "    pred_name = class_names[pred_idx]\n",
    "\n",
    "    # If a ground-truth label is provided, prepare a title showing “GT → Pred”; otherwise show only the prediction.\n",
    "    if true_label_idx is not None:\n",
    "        # Get the human-readable name of the ground-truth class.\n",
    "        true_name = class_names[true_label_idx]\n",
    "        # Build a title string that shows ground truth, prediction, and confidence percentage.\n",
    "        title = f\"{true_name} \\u2192 {pred_name} ({pred_conf:.2%})\"\n",
    "    else:\n",
    "        # Build a title string that shows only the predicted class and its confidence.\n",
    "        title = f\"{pred_name} ({pred_conf:.2%})\"\n",
    "\n",
    "    # Track whether this function needs to create its own figure for plotting.\n",
    "    created_fig = False\n",
    "    # If no Axes object is provided, create a new figure and axis for displaying the image.\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "        created_fig = True\n",
    "\n",
    "    # Show the original PIL image on the selected axis.\n",
    "    ax.imshow(img_pil)\n",
    "    # Hide the axis ticks and frame for a cleaner image display.\n",
    "    ax.axis(\"off\")\n",
    "    # Set the title above the image to show prediction information.\n",
    "    ax.set_title(title)\n",
    "\n",
    "    # If this function created the figure, display it immediately so the user can see the result.\n",
    "    if created_fig:\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small helper: pick one sample from each class in the test_dataset for later visualization.\n",
    "# Get the total number of classes from the dataset so we know how many samples to pick.\n",
    "num_classes = len(test_dataset.classes)\n",
    "# Store the human-readable class names from the dataset for later display.\n",
    "class_names = test_dataset.classes\n",
    "\n",
    "# Keep a list of indices where we first see each class in the dataset.\n",
    "# Initialize an empty list that will store the chosen sample index for each class.\n",
    "picked_indices = []\n",
    "#Use a Python set to record which class labels we have already seen (fast and beginner-friendly).\n",
    "seen_classes = set()\n",
    "\n",
    "# Loop over all samples with their index so we can grab the first occurrence of each class.\n",
    "for idx, (_, label_idx) in enumerate(test_dataset.samples):\n",
    "    # If this class label has not been seen before, we record this index as its representative sample.\n",
    "    if label_idx not in seen_classes:\n",
    "        # Add the new class label to the set so we do not pick it again.\n",
    "        seen_classes.add(label_idx)\n",
    "        # Save the index of this sample as the chosen example for this class.\n",
    "        picked_indices.append(idx)\n",
    "    # If we have already picked one sample for every class, we can stop the loop early to save time.\n",
    "    if len(picked_indices) == num_classes:\n",
    "        break\n",
    "\n",
    "# Print out the indices we picked so we can quickly check which samples are used.\n",
    "print(\"Picked indices:\", picked_indices)\n",
    "# Print the class names list so we can see the mapping from index to class label.\n",
    "print(\"Class names:\", class_names)\n",
    "\n",
    "# Draw one image for each class, with a title showing “GT → Pred (conf%)”.\n",
    "# Create a row of subplots, one axis per class, with a figure size that scales nicely with num_classes.\n",
    "fig, axes = plt.subplots(1, num_classes, figsize=(4 * num_classes, 4))\n",
    "\n",
    "# Loop over each subplot axis and its corresponding picked sample index.\n",
    "for ax, sample_idx in zip(axes, picked_indices):\n",
    "    # Get the image path and its label index from the test_dataset’s internal samples list.\n",
    "    img_path, label_idx = test_dataset.samples[sample_idx]\n",
    "\n",
    "    # Call our helper to run the model on this image and draw the prediction on the given axis.\n",
    "    show_prediction(\n",
    "        model,\n",
    "        image_path=img_path,\n",
    "        transform=transform,\n",
    "        class_names=class_names,\n",
    "        true_label_idx=label_idx,  # Pass the ground-truth label so the title can show “GT → Pred”.\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "# Adjust subplot spacing so titles and images do not overlap and everything looks clean.\n",
    "plt.tight_layout()\n",
    "# Finally display the whole figure so we can see one prediction example for each class.\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (silverpond .venv)",
   "language": "python",
   "name": "silverpond-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
